#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ØªØ³Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ TradingView
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup

async def test_current_links():
    """ØªØ³Øª Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„ÛŒ Ú©Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…"""
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    # ØªØ³Øª Ø¨Ø§ BTCUSDT
    symbol = "BTCUSDT"
    search_url = f"https://www.tradingview.com/symbols/{symbol}/ideas/"
    
    print(f"ðŸ” ØªØ³Øª URL: {search_url}")
    
    try:
        timeout = aiohttp.ClientTimeout(total=15)
        async with aiohttp.ClientSession(timeout=timeout, headers=headers) as session:
            async with session.get(search_url) as response:
                if response.status == 200:
                    content = await response.text()
                    soup = BeautifulSoup(content, 'html.parser')
                    
                    print("ðŸ”Ž Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ /chart/...")
                    
                    idea_links = soup.find_all('a', href=True)
                    processed_urls = set()
                    found_links = []
                    
                    for link in idea_links:
                        href = link.get('href', '')
                        
                        # Ù…Ù†Ø·Ù‚ ÙØ¹Ù„ÛŒ Ù…Ø§
                        if ('/chart/' in href and 
                            '/' in href.split('/chart/')[-1] and 
                            any(char.isalnum() for char in href) and 
                            len(href.split('/chart/')[-1]) > 10 and
                            '-' in href.split('/chart/')[-1] and
                            '#chart-view-comment-form' not in href):
                            
                            clean_href = href.split('#')[0]
                            analysis_url = clean_href if clean_href.startswith('http') else f"https://www.tradingview.com{clean_href}"
                            
                            if analysis_url not in processed_urls:
                                processed_urls.add(analysis_url)
                                found_links.append(analysis_url)
                                
                                # Ù†Ù…Ø§ÛŒØ´ Ø§ÙˆÙ„ÛŒÙ† 5 Ù„ÛŒÙ†Ú©
                                if len(found_links) <= 5:
                                    print(f"âœ… Ù„ÛŒÙ†Ú© {len(found_links)}: {analysis_url}")
                    
                    print(f"\nðŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯Ù‡: {len(found_links)}")
                    
                    if found_links:
                        print(f"\nðŸŽ¯ Ø§ÙˆÙ„ÛŒÙ† Ù„ÛŒÙ†Ú© Ø¨Ø±Ø§ÛŒ ØªØ³Øª: {found_links[0]}")
                        
                        # ØªØ³Øª Ú©Ø±Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† Ù„ÛŒÙ†Ú© Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ø§ÛŒÙ†Ú©Ù‡ redirect Ù…ÛŒâ€ŒØ´Ù‡ ÛŒØ§ Ù†Ù‡
                        print("\nðŸ” ØªØ³Øª Ø§ÙˆÙ„ÛŒÙ† Ù„ÛŒÙ†Ú©...")
                        await test_link_redirect(session, found_links[0])
                    
                else:
                    print(f"âŒ Ø®Ø·Ø§ÛŒ HTTP: {response.status}")
                    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§: {e}")

async def test_link_redirect(session, link):
    """ØªØ³Øª Ú©Ø±Ø¯Ù† Ø§ÛŒÙ†Ú©Ù‡ Ù„ÛŒÙ†Ú© Ø¨Ù‡ Ú©Ø¬Ø§ redirect Ù…ÛŒâ€ŒØ´Ù‡"""
    try:
        print(f"ðŸ“ Ø¯Ø±Ø­Ø§Ù„ ØªØ³Øª: {link}")
        
        async with session.get(link, allow_redirects=True) as response:
            final_url = str(response.url)
            print(f"ðŸŽ¯ URL Ù†Ù‡Ø§ÛŒÛŒ: {final_url}")
            
            if final_url != link:
                print("ðŸ”„ Redirect Ø´Ø¯Ù‡!")
            else:
                print("âœ… Direct link")
                
            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­ØªÙˆØ§ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† canonical URL
            if response.status == 200:
                content = await response.text()
                soup = BeautifulSoup(content, 'html.parser')
                
                # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ canonical link
                canonical = soup.find('link', rel='canonical')
                if canonical and canonical.get('href'):
                    canonical_url = canonical['href']
                    print(f"ðŸ”— Canonical URL: {canonical_url}")
                
                # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ og:url
                og_url = soup.find('meta', property='og:url')
                if og_url and og_url.get('content'):
                    og_url_content = og_url['content']
                    print(f"ðŸ“± OG URL: {og_url_content}")
                    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ù„ÛŒÙ†Ú©: {e}")

if __name__ == "__main__":
    asyncio.run(test_current_links())