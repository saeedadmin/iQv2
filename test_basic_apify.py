#!/usr/bin/env python3
"""
Test basic Apify functionality with a known working actor
"""

from apify_client import ApifyClient
import json

def test_basic_functionality():
    client = ApifyClient("apify_api_TlFKaUvvz0nTU5B13YdisQHTrcr08L1L7IKc")
    
    print("ğŸš€ Testing basic Apify functionality...")
    
    # First, let's check our account status
    try:
        user_info = client.user('me').get()
        print(f"ğŸ‘¤ Account: {user_info.get('username', 'N/A')}")
        print(f"ğŸ’° Monthly usage: ${user_info.get('monthlyChargedUsd', 0)}")
        print(f"ğŸ†” User ID: {user_info.get('id', 'N/A')}")
    except Exception as e:
        print(f"âš ï¸ Couldn't get user info: {e}")
    
    # Try a simple working actor - the crawler
    run_input = {
        "startUrls": [
            {"url": "https://t.me/s/Shervin_Trading"}
        ],
        "maxRequestsPerCrawl": 5,
        "requestTimeoutSecs": 30
    }
    
    try:
        print("\nâ³ Testing with crawlee-cheerio-crawler...")
        run = client.actor("crawlee/cheerio-crawler").call(run_input=run_input, timeout_secs=120)
        
        print(f"âœ… Success! Run ID: {run['id']}")
        print(f"ğŸ“Š Status: {run['status']}")
        
        # Get usage stats
        run_info = client.run(run['id']).get()
        stats = run_info.get('stats', {})
        print(f"ğŸ’° Cost: {stats.get('computeUnits', 'N/A')} compute units")
        print(f"â±ï¸ Duration: {stats.get('runTimeSecs', 'N/A')} seconds")
        
        # Get results
        dataset_items = client.dataset(run['defaultDatasetId']).list_items().items
        print(f"ğŸ“Š Items scraped: {len(dataset_items)}")
        
        if dataset_items:
            # Save results
            with open('/workspace/crawlee_test_results.json', 'w', encoding='utf-8') as f:
                json.dump(dataset_items, f, ensure_ascii=False, indent=2)
            
            print("ğŸ’¾ Results saved to crawlee_test_results.json")
            
            # Show sample
            print("\nğŸ“ Sample result:")
            sample = dataset_items[0]
            for key, value in list(sample.items())[:3]:
                print(f"   {key}: {str(value)[:150]}...")
                
            return True
        else:
            print("âš ï¸ No results found")
            return False
            
    except Exception as e:
        print(f"âŒ Crawler test failed: {str(e)}")
        
        # If that fails, let's try something even simpler
        print("\nğŸ”„ Trying alternative simple test...")
        
        try:
            # Try getting our runs to see if API works at all
            my_runs = client.runs().list(limit=5).items
            print(f"âœ… API connection works! Found {len(my_runs)} recent runs")
            
            if my_runs:
                print("ğŸ“‹ Recent runs:")
                for run in my_runs[:3]:
                    print(f"   - {run['id']}: {run['status']} ({run.get('actorId', 'N/A')})")
                    
            return True
            
        except Exception as e2:
            print(f"âŒ Even basic API call failed: {str(e2)}")
            return False

if __name__ == "__main__":
    success = test_basic_functionality()
    
    if success:
        print("\nğŸ‰ Apify API is working!")
    else:
        print("\nâŒ Apify API connection failed")