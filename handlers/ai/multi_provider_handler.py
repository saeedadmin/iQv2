#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Ù…Ø§Ú˜ÙˆÙ„ Ù…Ø¯ÛŒØ±ÛŒØª Ú†Øª Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (Ù†Ø³Ø®Ù‡ Ù¾ÛŒØ´Ø±ÙØªÙ‡)
Ù†ÙˆÛŒØ³Ù†Ø¯Ù‡: MiniMax Agent

Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§:
- Multi-API rotation Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯
- Rate limiting Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ù‡Ø± API
- Automatic fallback Ø¨Ù‡ API Ø¨Ø¹Ø¯ÛŒ
- Load balancing Ø¨ÛŒÙ† API Ù‡Ø§
- Health checking
- Translation Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ø³Ø±ÙˆÛŒØ³
- Ú†Ø±Ø®Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨ÛŒÙ† Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯
"""

import logging
import requests
import html
import re
import datetime
import time
import asyncio
from typing import Optional, Dict, Any, List
import os
import json
import random
from dotenv import load_dotenv

# Ù„ÙˆØ¯ Ú©Ø±Ø¯Ù† Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ Ø§Ø² ÙØ§ÛŒÙ„ .env
load_dotenv()

logger = logging.getLogger(__name__)

class KeyRotator:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ú†Ø±Ø®Ø´ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ API"""
    
    def __init__(self, keys: List[str], provider_name: str):
        self.keys = keys
        self.provider_name = provider_name
        self.current_key_index = 0
        self.failed_keys = set()
        self.usage_stats = {key: 0 for key in keys}
        self.last_used = {key: None for key in keys}
        
    def get_next_key(self) -> Optional[str]:
        """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø§ Ú†Ø±Ø®Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯"""
        if not self.keys:
            return None
            
        # Ø§Ú¯Ø± Ù‡Ù…Ù‡ Ú©Ù„ÛŒØ¯Ù‡Ø§ Ø®Ø±Ø§Ø¨ Ù‡Ø³ØªÙ†Ø¯ØŒ reset Ú©Ù†
        if len(self.failed_keys) >= len(self.keys):
            self.failed_keys.clear()
        
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ú©Ù„ÛŒØ¯ Ù…Ø¹ØªØ¨Ø±
        for i in range(len(self.keys)):
            key = self.keys[(self.current_key_index + i) % len(self.keys)]
            
            if key in self.failed_keys:
                continue
                
            self.current_key_index = (self.current_key_index + i + 1) % len(self.keys)
            self.last_used[key] = datetime.datetime.now()
            return key
            
        return None
    
    def mark_key_failed(self, key: str):
        """Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ú©Ù„ÛŒØ¯ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø®Ø±Ø§Ø¨"""
        self.failed_keys.add(key)
    
    def mark_key_success(self, key: str):
        """Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ú©Ù„ÛŒØ¯ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…ÙˆÙÙ‚"""
        if key in self.failed_keys:
            self.failed_keys.remove(key)
        self.usage_stats[key] = self.usage_stats.get(key, 0) + 1
    
    def get_stats(self) -> Dict[str, Any]:
        """Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒØ¯Ù‡Ø§"""
        return {
            "total_keys": len(self.keys),
            "failed_keys": len(self.failed_keys),
            "usage_stats": self.usage_stats.copy(),
            "last_used": self.last_used.copy()
        }

class MultiProviderHandler:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ú†Øª Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ"""
    
    def __init__(self, db_manager=None):
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ handler Ø¨Ø§ Ú†Ù†Ø¯ÛŒÙ† provider"""
        self.db = db_manager
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Rate Limiting
        self.rate_limit_messages = 20  # ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù… Ù…Ø¬Ø§Ø²
        self.rate_limit_seconds = 60  # Ø¯Ø± Ú†Ù†Ø¯ Ø«Ø§Ù†ÛŒÙ‡
        self.user_message_times = {}
        
        # ØªØ¹Ø±ÛŒÙ Providers Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ù…ØªØ¹Ø¯Ø¯
        self.providers = self._initialize_providers()
        self.key_rotators = self._initialize_key_rotators()
        self.current_provider_index = 0
        self.failed_providers = set()  # Ù„ÛŒØ³Øª providers Ø®Ø±Ø§Ø¨
        
        # Retry Settings
        self.max_retries = 3
        self.retry_delay_base = 2
        
        # API Quota Tracking
        self.api_calls_today = {}
        self.last_reset_date = datetime.datetime.now().date()
        
        # Performance Tracking
        self.provider_performance = {}
        self.last_provider_test = {}
    
    def _initialize_providers(self) -> Dict[str, Dict]:
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ providers"""
        return {
            "groq": {
                "name": "Groq",
                "type": "openai_compatible",
                "base_url": "https://api.groq.com/openai/v1",
                "models": ["llama-3.3-70b-versatile", "llama-3.1-8b-instant", "mixtral-8x7b-32768"],
                "rate_limits": {
                    "requests_per_minute": 1000,
                    "requests_per_day": 14400,
                    "tokens_per_minute": 6000
                },
                "headers": {
                    "Content-Type": "application/json",
                    "Accept": "application/json"
                },
                "priority": 1,  # Ø¨Ø§Ù„Ø§ØªØ±ÛŒÙ† Ø§ÙˆÙ„ÙˆÛŒØª (Ø³Ø±ÛŒØ¹â€ŒØªØ±ÛŒÙ†)
                "available": True
            },
            "cerebras": {
                "name": "Cerebras", 
                "type": "cerebras_sdk",
                "base_url": "https://api.cerebras.ai/v1",
                "models": ["qwen-3-235b-a22b-instruct-2507", "llama-3.3-70b"],
                "rate_limits": {
                    "requests_per_minute": 30,
                    "requests_per_day": 14400,
                    "tokens_per_minute": 60000
                },
                "headers": {
                    "Content-Type": "application/json",
                    "Accept": "application/json"
                },
                "priority": 2,  # Ø¯ÙˆÙ…ÛŒÙ† Ø§ÙˆÙ„ÙˆÛŒØª
                "available": True
            },
            "gemini": {
                "name": "Google Gemini",
                "type": "gemini",
                "base_url": "https://generativelanguage.googleapis.com/v1beta",
                "models": ["gemini-2.0-flash-exp", "gemini-2.5-flash-lite"],
                "rate_limits": {
                    "requests_per_minute": 10,
                    "requests_per_day": 50,  # Ù‡Ø± Ú©Ù„ÛŒØ¯ 50
                    "tokens_per_minute": 250000
                },
                "headers": {
                    "Content-Type": "application/json"
                },
                "priority": 3,  # Ø³ÙˆÙ…ÛŒÙ† Ø§ÙˆÙ„ÙˆÛŒØª
                "available": True
            },
            "openrouter": {
                "name": "OpenRouter",
                "type": "openai_compatible", 
                "base_url": "https://openrouter.ai/api/v1",
                "models": ["deepseek/deepseek-chat-v3.1", "qwen/qwen-2.5-72b-instruct"],
                "rate_limits": {
                    "requests_per_minute": 20,
                    "requests_per_day": 50,
                    "tokens_per_minute": 8000
                },
                "headers": {
                    "Content-Type": "application/json",
                    "HTTP-Referer": "https://yourapp.com",
                    "X-Title": "Telegram Bot"
                },
                "priority": 4,
                "available": True
            },
            "cohere": {
                "name": "Cohere",
                "type": "cohere",
                "base_url": "https://api.cohere.ai/v1",
                "models": ["command-r", "command-r-plus"],
                "rate_limits": {
                    "requests_per_minute": 20,
                    "requests_per_day": 1000,  # Per month
                    "tokens_per_minute": 5000
                },
                "headers": {
                    "Content-Type": "application/json",
                    "Authorization": "Bearer"
                },
                "priority": 5,
                "available": True
            }
        }
    
    def _initialize_key_rotators(self) -> Dict[str, KeyRotator]:
        """Ù…Ù‚Ø¯Ø§Ø±Ø¯Ù‡ÛŒ Ú†Ø±Ø®Ø´ Ú©Ù„ÛŒØ¯Ù‡Ø§"""
        rotators = {}
        
        # Groq keys
        groq_keys = []
        if os.getenv('GROQ_API_KEY'):
            groq_keys.append(os.getenv('GROQ_API_KEY'))
        if os.getenv('GROQ_API_KEY_2'):
            groq_keys.append(os.getenv('GROQ_API_KEY_2'))
        if groq_keys:
            rotators["groq"] = KeyRotator(groq_keys, "groq")
        
        # Cerebras keys
        cerebras_keys = []
        if os.getenv('CEREBRAS_API_KEY'):
            cerebras_keys.append(os.getenv('CEREBRAS_API_KEY'))
        if os.getenv('CEREBRAS_API_KEY_2'):
            cerebras_keys.append(os.getenv('CEREBRAS_API_KEY_2'))
        if cerebras_keys:
            rotators["cerebras"] = KeyRotator(cerebras_keys, "cerebras")
        
        # Gemini keys
        gemini_keys = []
        if os.getenv('GEMINI_API_KEY'):
            gemini_keys.append(os.getenv('GEMINI_API_KEY'))
        if os.getenv('GEMINI_API_KEY_2'):
            gemini_keys.append(os.getenv('GEMINI_API_KEY_2'))
        if gemini_keys:
            rotators["gemini"] = KeyRotator(gemini_keys, "gemini")
        
        # OpenRouter keys (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
        if os.getenv('OPENROUTER_API_KEY'):
            rotators["openrouter"] = KeyRotator([os.getenv('OPENROUTER_API_KEY')], "openrouter")
        
        # Cohere keys (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
        if os.getenv('COHERE_API_KEY'):
            rotators["cohere"] = KeyRotator([os.getenv('COHERE_API_KEY')], "cohere")
        
        return rotators
    
    def get_next_available_provider(self) -> Optional[str]:
        """Ø¯Ø±ÛŒØ§ÙØª provider Ø¨Ø¹Ø¯ÛŒ Ú©Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ø§Ø³Øª (Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÙˆÙ„ÙˆÛŒØª)"""
        if not self.providers:
            return None
            
        # Ø§Ú¯Ø± Ù‡Ù…Ù‡ providers Ø®Ø±Ø§Ø¨ Ù‡Ø³ØªÙ†Ø¯ØŒ reset Ú©Ù†
        if len(self.failed_providers) >= len(self.providers):
            self.failed_providers.clear()
        
        # Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ providers Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÙˆÙ„ÙˆÛŒØª Ùˆ performance
        available_providers = []
        for name, provider in self.providers.items():
            if name not in self.failed_providers and name in self.key_rotators:
                available_providers.append((name, provider))
        
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† provider ÙØ¹Ø§Ù„ Ù†Ø¨Ø§Ø´Ø¯
        if not available_providers:
            return None
        
        # Ø§Ù†ØªØ®Ø§Ø¨ provider Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÙˆÙ„ÙˆÛŒØª Ùˆ performance
        best_provider = None
        best_score = float('-inf')
        
        for name, provider in available_providers:
            priority_score = -provider.get("priority", 999)  # Ø§ÙˆÙ„ÙˆÛŒØª Ú©Ù…ØªØ± = Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ±
            
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ù…ØªÛŒØ§Ø² performance (Ø§Ú¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ø´Ø¯)
            perf_data = self.provider_performance.get(name, {})
            success_rate = perf_data.get("success_rate", 0.5)  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ 50%
            avg_response_time = perf_data.get("avg_response_time", 5.0)  # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ 5 Ø«Ø§Ù†ÛŒÙ‡
            
            # Performance score: success rate Ø¨Ø§Ù„Ø§ Ùˆ response time Ú©Ù… = Ø§Ù…ØªÛŒØ§Ø² Ø¨ÛŒØ´ØªØ±
            performance_score = success_rate * 10 - avg_response_time
            
            total_score = priority_score + performance_score
            
            if total_score > best_score:
                best_score = total_score
                best_provider = name
        
        if best_provider:
            logger.debug(f"âœ… Selected provider by priority + performance: {best_provider}")
            return best_provider
        
        return None
    
    async def _make_api_request(self, provider_name: str, messages: List[Dict], model: str = None) -> Dict[str, Any]:
        """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ provider Ù…Ø´Ø®Øµ"""
        provider = self.providers[provider_name]
        provider_type = provider.get("type")
        
        # Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„ÛŒØ¯ Ù…Ù†Ø§Ø³Ø¨
        rotator = self.key_rotators.get(provider_name)
        if not rotator:
            raise Exception(f"No key rotator Ø¨Ø±Ø§ÛŒ {provider_name}")
        
        api_key = rotator.get_next_key()
        if not api_key:
            raise Exception(f"No available API keys for {provider_name}")
        
        if not model:
            model = provider["models"][0]  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÙˆÙ„ÛŒÙ† Ù…Ø¯Ù„
        
        try:
            # Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ provider
            if provider_type == "openai_compatible":
                result = await self._make_openai_request(api_key, provider, messages, model)
            elif provider_type == "cerebras_sdk":
                result = await self._make_cerebras_request(api_key, provider, messages, model)
            elif provider_type == "gemini":
                result = await self._make_gemini_request(api_key, provider, messages, model)
            elif provider_type == "cohere":
                result = await self._make_cohere_request(api_key, provider, messages, model)
            else:
                raise Exception(f"Ù†ÙˆØ¹ provider Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {provider_type}")
            
            # Ù…ÙˆÙÙ‚ÛŒØª - Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±
            rotator.mark_key_success(api_key)
            self.api_calls_today[provider_name] = self.api_calls_today.get(provider_name, 0) + 1
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ performance data
            self._update_performance_data(provider_name, True, result.get("response_time", 1.0))
            
            return {
                "success": True,
                "content": result["content"],
                "provider": provider_name,
                "model": model,
                "api_key_used": api_key[:10] + "...",
                "tokens_used": result.get("tokens_used", 0),
                "prompt_tokens": result.get("prompt_tokens", 0),
                "completion_tokens": result.get("completion_tokens", 0),
                "response_time": result.get("response_time", 0)
            }
            
        except Exception as e:
            # Ø®Ø·Ø§ - Ø¹Ù„Ø§Ù…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ Ú©Ù„ÛŒØ¯ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ø®Ø±Ø§Ø¨
            rotator.mark_key_failed(api_key)
            
            # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ performance data
            self._update_performance_data(provider_name, False, 0)
            
            raise
    
    async def _make_openai_request(self, api_key: str, provider: Dict, messages: List[Dict], model: str) -> Dict[str, Any]:
        """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ OpenAI-compatible API"""
        headers = provider.get("headers", {}).copy()
        headers["Authorization"] = f"Bearer {api_key}"
        
        payload = {
            "model": model,
            "messages": messages,
            "max_tokens": 1000,
            "temperature": 0.7
        }
        
        url = f"{provider['base_url']}/chat/completions"
        
        start_time = time.time()
        response = requests.post(
            url=url,
            headers=headers,
            json=payload,
            timeout=30
        )
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø§Ø² response
            usage = result.get("usage", {})
            tokens_used = usage.get("total_tokens", 0)
            
            return {
                "content": content, 
                "response_time": response_time,
                "tokens_used": tokens_used,
                "prompt_tokens": usage.get("prompt_tokens", 0),
                "completion_tokens": usage.get("completion_tokens", 0)
            }
        else:
            raise Exception(f"API Error {response.status_code}: {response.text}")
    
    async def _make_cerebras_request(self, api_key: str, provider: Dict, messages: List[Dict], model: str) -> Dict[str, Any]:
        """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Cerebras Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø±Ø³Ù…ÛŒ"""
        try:
            from cerebras.cloud.sdk import Cerebras
            
            # Ø§ÛŒØ¬Ø§Ø¯ client
            client = Cerebras(api_key=api_key)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Cerebras
            system_content = ""
            user_messages = []
            
            for msg in messages:
                if msg["role"] == "system":
                    system_content = msg["content"]
                else:
                    user_messages.append(msg["content"])
            
            user_content = "\n".join(user_messages)
            
            start_time = time.time()
            
            # Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª
            stream = client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": system_content
                    },
                    {
                        "role": "user", 
                        "content": user_content
                    }
                ],
                model=model,
                stream=False,  # Non-streaming Ø¨Ø±Ø§ÛŒ Ø³Ø§Ø¯Ú¯ÛŒ
                max_completion_tokens=1000,
                temperature=0.7,
                top_p=0.8
            )
            
            response_time = time.time() - start_time
            
            # Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø§Ø³Ø®
            content = stream.choices[0].message.content
            return {"content": content, "response_time": response_time}
            
        except ImportError:
            # Fallback Ø¨Ù‡ REST API
            headers = provider.get("headers", {}).copy()
            headers["Authorization"] = f"Bearer {api_key}"
            
            payload = {
                "model": model,
                "messages": messages,
                "max_tokens": 1000,
                "temperature": 0.7
            }
            
            url = f"{provider['base_url']}/chat/completions"
            
            start_time = time.time()
            response = requests.post(
                url=url,
                headers=headers,
                json=payload,
                timeout=30
            )
            response_time = time.time() - start_time
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø§Ø² OpenAI-compatible response
                usage = result.get("usage", {})
                tokens_used = usage.get("total_tokens", 0)
                
                return {
                    "content": content, 
                    "response_time": response_time,
                    "tokens_used": tokens_used,
                    "prompt_tokens": usage.get("prompt_tokens", 0),
                    "completion_tokens": usage.get("completion_tokens", 0)
                }
            else:
                raise Exception(f"API Error {response.status_code}: {response.text}")
    
    async def _make_gemini_request(self, api_key: str, provider: Dict, messages: List[Dict], model: str) -> Dict[str, Any]:
        """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Gemini API"""
        headers = provider.get("headers", {}).copy()
        headers["x-goog-api-key"] = api_key
        
        # ØªØ¨Ø¯ÛŒÙ„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª Gemini
        content = "\n".join([msg["content"] for msg in messages if msg["role"] != "system"])
        
        payload = {
            "contents": [{
                "parts": [{"text": content}]
            }],
            "generationConfig": {
                "maxOutputTokens": 1000,
                "temperature": 0.7
            }
        }
        
        url = f"{provider['base_url']}/models/{model}:generateContent"
        
        start_time = time.time()
        response = requests.post(
            url=url,
            headers=headers,
            json=payload,
            timeout=30
        )
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            content = result["candidates"][0]["content"]["parts"][0]["text"]
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø§Ø² Gemini response
            usage = result.get("usageMetadata", {})
            tokens_used = usage.get("totalTokenCount", 0)
            
            return {
                "content": content, 
                "response_time": response_time,
                "tokens_used": tokens_used,
                "prompt_tokens": usage.get("promptTokenCount", 0),
                "completion_tokens": usage.get("candidatesTokenCount", 0)
            }
        else:
            raise Exception(f"API Error {response.status_code}: {response.text}")
    
    async def _make_cohere_request(self, api_key: str, provider: Dict, messages: List[Dict], model: str) -> Dict[str, Any]:
        """Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ Cohere API"""
        headers = provider.get("headers", {}).copy()
        headers["Authorization"] = f"Bearer {api_key}"
        
        payload = {
            "model": model,
            "message": messages[-1]["content"] if messages else "",
            "chat_history": messages[:-1] if len(messages) > 1 else []
        }
        
        url = f"{provider['base_url']}/chat"
        
        start_time = time.time()
        response = requests.post(
            url=url,
            headers=headers,
            json=payload,
            timeout=30
        )
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            content = result["reply"]
            return {"content": content, "response_time": response_time}
        else:
            raise Exception(f"API Error {response.status_code}: {response.text}")
    
    def _update_performance_data(self, provider_name: str, success: bool, response_time: float):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ performance"""
        if provider_name not in self.provider_performance:
            self.provider_performance[provider_name] = {
                "total_requests": 0,
                "successful_requests": 0,
                "total_response_time": 0,
                "success_rate": 0.0,
                "avg_response_time": 0.0
            }
        
        data = self.provider_performance[provider_name]
        data["total_requests"] += 1
        
        if success:
            data["successful_requests"] += 1
            data["total_response_time"] += response_time
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ success rate Ùˆ average response time
        data["success_rate"] = data["successful_requests"] / data["total_requests"]
        if data["successful_requests"] > 0:
            data["avg_response_time"] = data["total_response_time"] / data["successful_requests"]
        else:
            data["avg_response_time"] = 0
    
    def _check_user_rate_limit(self, user_id: int) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ rate limit Ú©Ø§Ø±Ø¨Ø±"""
        current_time = datetime.datetime.now()
        
        if user_id not in self.user_message_times:
            self.user_message_times[user_id] = []
        
        # Ø­Ø°Ù Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
        cutoff_time = current_time - datetime.timedelta(seconds=self.rate_limit_seconds)
        self.user_message_times[user_id] = [
            t for t in self.user_message_times[user_id] 
            if t > cutoff_time
        ]
        
        # Ø¨Ø±Ø±Ø³ÛŒ ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
        message_count = len(self.user_message_times[user_id])
        return message_count < self.rate_limit_messages
    
    def _record_user_message(self, user_id: int):
        """Ø«Ø¨Øª Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±"""
        current_time = datetime.datetime.now()
        if user_id not in self.user_message_times:
            self.user_message_times[user_id] = []
        self.user_message_times[user_id].append(current_time)
    
    async def send_message(self, message: str, user_id: int = None) -> Dict[str, Any]:
        """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² provider Ù…ÙˆØ¬ÙˆØ¯ Ùˆ Ø­Ø§ÙØ¸Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡"""
        # Ø¨Ø±Ø±Ø³ÛŒ rate limit Ú©Ø§Ø±Ø¨Ø±
        if user_id and not self._check_user_rate_limit(user_id):
            return {
                "success": False,
                "error": "Rate limit exceeded for user",
                "content": "Ø´Ù…Ø§ Ø²ÛŒØ§Ø¯ÛŒ Ù¾ÛŒØ§Ù… ÙØ±Ø³ØªØ§Ø¯Ù‡â€ŒØ§ÛŒØ¯ØŒ Ù„Ø·ÙØ§Ù‹ Ú©Ù…ÛŒ ØµØ¨Ø± Ú©Ù†ÛŒØ¯."
            }
        
        # Ù¾ÛŒØ§Ù… Ø³ÛŒØ³ØªÙ… Ø¨Ø±Ø§ÛŒ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒÛŒ AI
        system_prompt = "ØªÙˆ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù‡Ø³ØªÛŒ Ú©Ù‡ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡ÛŒ. Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒØª Ù…ÙÛŒØ¯ØŒ Ø¯Ù‚ÛŒÙ‚ Ùˆ Ú©ÙˆØªØ§Ù‡ Ø¨Ø§Ø´Ø¯."
        
        # Ø´Ø±ÙˆØ¹ Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
        messages = [{"role": "system", "content": system_prompt}]
        
        # Ø§Ú¯Ø± user_id Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³ØªØŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ø±Ø§ Ø§Ø² database Ø¨Ø®ÙˆØ§Ù†
        if user_id and self.db:
            try:
                chat_history = self.db.get_chat_history(user_id, limit=50)
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¨Ù‡ messages (ØªØ¨Ø¯ÛŒÙ„ role Ø¨Ù‡ ÙØ±Ù…Øª ØµØ­ÛŒØ­ Ø¨Ø±Ø§ÛŒ API Ù‡Ø§)
                for msg in chat_history:
                    # ØªØ¨Ø¯ÛŒÙ„ role Ø§Ø² database Ø¨Ù‡ format Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø± API Ù‡Ø§
                    role = msg['role']
                    if role == 'model':
                        role = 'assistant'  # Groq Ùˆ Ø¨ÛŒØ´ØªØ± API Ù‡Ø§ Ù†Ù‚Ø´ 'assistant' Ø±Ø§ Ù…ÛŒâ€ŒÙ¾Ø°ÛŒØ±Ù†Ø¯
                    
                    messages.append({
                        "role": role,
                        "content": msg['message_text']
                    })
                
                logger.info(f"ğŸ“š Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {len(chat_history)} Ù¾ÛŒØ§Ù… Ø§Ø² ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø± {user_id}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª: {e}")
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ Ú©Ø§Ø±Ø¨Ø±
        messages.append({"role": "user", "content": message})
        
        # ØªÙ„Ø§Ø´ Ø¨Ø§ providers Ù…Ø®ØªÙ„Ù
        for attempt in range(len(self.providers)):
            provider_name = self.get_next_available_provider()
            
            if not provider_name:
                return {
                    "success": False,
                    "error": "No available providers",
                    "content": "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‡ÛŒÚ† Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª. Ù„Ø·ÙØ§Ù‹ Ø¨Ø¹Ø¯Ø§Ù‹ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯."
                }
            
            try:
                result = await self._make_api_request(provider_name, messages)
                
                # Record user message time
                if user_id:
                    self._record_user_message(user_id)
                
                # Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ùˆ Ù¾Ø§Ø³Ø® AI Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ (Ø§Ú¯Ø± database Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª)
                if user_id and self.db:
                    try:
                        self.db.add_chat_message(user_id, 'user', message)
                        self.db.add_chat_message(user_id, 'model', result["content"])
                        logger.info(f"ğŸ’¾ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø± {user_id} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
                    except Exception as e:
                        logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª: {e}")
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ return
                tokens_used = result.get("tokens_used", 0)
                prompt_tokens = result.get("prompt_tokens", 0)
                completion_tokens = result.get("completion_tokens", 0)
                response_time = result.get("response_time", 0)
                
                logger.info(f"ğŸ¯ Provider Success - {result['provider']}:")
                logger.info(f"   ğŸ“Š Total Tokens: {tokens_used}")
                logger.info(f"   ğŸ“ Prompt Tokens: {prompt_tokens}")
                logger.info(f"   âœï¸ Completion Tokens: {completion_tokens}")
                logger.info(f"   â±ï¸ Response Time: {response_time:.2f}s")
                
                return {
                    "success": True,
                    "content": result["content"],
                    "provider": result["provider"],
                    "model": result["model"],
                    "api_key_used": result.get("api_key_used", "N/A"),
                    "tokens_used": tokens_used,
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "response_time": response_time
                }
                
            except Exception as e:
                logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± provider {provider_name}: {e}")
                continue
        
        return {
            "success": False, 
            "error": "All providers failed",
            "content": "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‡ÛŒÚ† Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
        }
    
    async def translate_multiple_texts(self, texts: List[str]) -> List[str]:
        """ØªØ±Ø¬Ù…Ù‡ Ú¯Ø±ÙˆÙ‡ÛŒ Ù…ØªÙˆÙ† Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ"""
        if not texts:
            return []
        
        translated_texts = []
        
        # Ø³ÛŒØ³ØªÙ… Ù¾Ø±Ø§Ù…Ù¾Øª Ù…Ø´Ø®Øµ Ø¨Ø±Ø§ÛŒ ØªØ±Ø¬Ù…Ù‡
        translation_system_prompt = "ØªÙˆ ÛŒÚ© Ù…ØªØ±Ø¬Ù… Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ Ù‡Ø³ØªÛŒ Ú©Ù‡ ÙÙ‚Ø· Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡ÛŒ. Ù‡Ø±Ú¯Ø² Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ÛŒØ§ Ù‡Ø± Ø²Ø¨Ø§Ù† Ø¯ÛŒÚ¯Ø±ÛŒ Ù†ÙˆØ´ØªÙ‡ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯. ÙÙ‚Ø· ØªØ±Ø¬Ù…Ù‡ ÙØ§Ø±Ø³ÛŒ Ø§Ø±Ø§Ø¦Ù‡ Ø¨Ø¯Ù‡."
        
        for text in texts:
            try:
                # Ù¾ÛŒØ§Ù… ØªØ±Ø¬Ù…Ù‡ Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ù¾Ø±Ø§Ù…Ù¾Øª Ù…Ø´Ø®Øµ
                translation_prompt = f"Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø²ÛŒØ± Ø±Ø§ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ ØªØ±Ø¬Ù…Ù‡ Ú©Ù† Ùˆ ÙÙ‚Ø· ØªØ±Ø¬Ù…Ù‡ ÙØ§Ø±Ø³ÛŒ Ø¨Ø¯Ù‡:\n\n{text}"
                
                # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ Ø¯Ø§Ø®Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù¾ÛŒØ§Ù… Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ù¾Ø±Ø§Ù…Ù¾Øª Ù…Ø´Ø®Øµ
                result = await self._send_message_with_custom_prompt(translation_prompt, translation_system_prompt)
                
                if result["success"]:
                    # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ù¾Ø§Ø³Ø® Ø§Ø² Ù…ØªÙ† Ø§Ø¶Ø§ÙÛŒ
                    translated_content = result["content"].strip()
                    translated_texts.append(translated_content)
                else:
                    translated_texts.append(text)  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªÙ† Ø§ØµÙ„ÛŒ
                    
            except Exception as e:
                translated_texts.append(text)  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªÙ† Ø§ØµÙ„ÛŒ
        
        return translated_texts
    
    async def _send_message_with_custom_prompt(self, message: str, custom_system_prompt: str) -> Dict[str, Any]:
        """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ø§ Ø³ÛŒØ³ØªÙ… Ù¾Ø±Ø§Ù…Ù¾Øª Ø³ÙØ§Ø±Ø´ÛŒ"""
        messages = [
            {"role": "system", "content": custom_system_prompt},
            {"role": "user", "content": message}
        ]
        
        # ØªÙ„Ø§Ø´ Ø¨Ø§ providers Ù…Ø®ØªÙ„Ù
        for attempt in range(len(self.providers)):
            provider_name = self.get_next_available_provider()
            
            if not provider_name:
                return {
                    "success": False,
                    "error": "No available providers",
                    "content": "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‡ÛŒÚ† Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
                }
            
            try:
                result = await self._make_api_request(provider_name, messages)
                
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¨Ù‡ return
                tokens_used = result.get("tokens_used", 0)
                prompt_tokens = result.get("prompt_tokens", 0)
                completion_tokens = result.get("completion_tokens", 0)
                response_time = result.get("response_time", 0)
                
                return {
                    "success": True,
                    "content": result["content"],
                    "provider": result["provider"],
                    "model": result["model"],
                    "api_key_used": result.get("api_key_used", "N/A"),
                    "tokens_used": tokens_used,
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "response_time": response_time
                }
                
            except Exception as e:
                continue
        
        return {
            "success": False, 
            "error": "All providers failed",
            "content": "Ù…ØªØ£Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‡ÛŒÚ† Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
        }
    
    def reset_daily_quotas(self):
        """Reset Ú©ÙˆØ¦ÙˆØªØ§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡"""
        current_date = datetime.datetime.now().date()
        if current_date != self.last_reset_date:
            self.api_calls_today.clear()
            self.last_reset_date = current_date
    
    def get_status(self) -> Dict[str, Any]:
        """Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª providers"""
        status = {
            "total_providers": len(self.providers),
            "available_providers": len([p for p in self.providers.values() if p.get("api_key")]),
            "failed_providers": list(self.failed_providers),
            "quota_status": {},
            "key_rotator_stats": {},
            "performance_stats": self.provider_performance.copy()
        }
        
        for name, provider in self.providers.items():
            daily_calls = self.api_calls_today.get(name, 0)
            max_daily = provider.get("rate_limits", {}).get("requests_per_day", 0)
            
            status["quota_status"][name] = {
                "calls_today": daily_calls,
                "max_daily": max_daily,
                "available": name not in self.failed_providers,
                "priority": provider.get("priority", 999)
            }
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢Ù…Ø§Ø± key rotators
        for name, rotator in self.key_rotators.items():
            status["key_rotator_stats"][name] = rotator.get_stats()
        
        return status