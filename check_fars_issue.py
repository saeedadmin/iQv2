#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø´Ú©Ù„ Ù…Ù†Ø¨Ø¹ ÙØ§Ø±Ø³ Ùˆ Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ù…Ù†Ø§Ø³Ø¨
"""

import asyncio
import aiohttp
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def check_fars_issue():
    """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø´Ú©Ù„ Ù…Ù†Ø¨Ø¹ ÙØ§Ø±Ø³"""
    url = "https://www.farsnews.ir/rss.xml"
    
    logger.info("ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø´Ú©Ù„ Ù…Ù†Ø¨Ø¹ ÙØ§Ø±Ø³...")
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(url, timeout=15) as response:
                content = await response.text()
                logger.info(f"ğŸ“ Ø·ÙˆÙ„ Ù…Ø­ØªÙˆØ§: {len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
                logger.info(f"ğŸ”— URL: {response.url}")
                logger.info(f"ğŸ“¡ Status: {response.status}")
                
                # Ù†Ù…Ø§ÛŒØ´ Ø¨Ø®Ø´ÛŒ Ø§Ø² Ù…Ø­ØªÙˆØ§ Ø¨Ø±Ø§ÛŒ debug
                lines = content.split('\n')
                logger.info(f"ğŸ“„ ØªØ¹Ø¯Ø§Ø¯ Ø®Ø·ÙˆØ·: {len(lines)}")
                logger.info("ğŸ” Ø§ÙˆÙ„ÛŒÙ† 10 Ø®Ø·:")
                for i, line in enumerate(lines[:10]):
                    logger.info(f"  {i+1}: {line[:100]}...")
                
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø®Ø·Ø§Ù‡Ø§ÛŒ XML
                if "mismatched tag" in content:
                    logger.error("âŒ Ø®Ø·Ø§ÛŒ XML mismatched tag Ù¾ÛŒØ¯Ø§ Ø´Ø¯")
                
                if "<html" in content.lower():
                    logger.error("âŒ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ø¯ Ø¨Ù‡ HTML redirect Ø´Ø¯Ù‡ØŒ Ù†Ù‡ RSS")
                
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø§: {e}")

async def find_replacement_source():
    """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ù†Ø¨Ø¹ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³"""
    alternatives = [
        {
            'name': 'Ø§ÛŒØ±Ù†Ø§ (IRNA) - Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† ÙØ§Ø±Ø³',
            'url': 'https://www.irna.ir/rss/fa/1',
            'limit': 2
        },
        {
            'name': 'Ø§ÛŒØ±Ù†Ø§ Ø³ÛŒØ§Ø³ÛŒ',
            'url': 'https://www.irna.ir/rss/fa/3',
            'limit': 2
        },
        {
            'name': 'Ø¨Ø±Ù†Ø§ Ø®Ø¨Ø±Ú¯Ø²Ø§Ø±ÛŒ',
            'url': 'https://www.borna.news/rss',
            'limit': 2
        },
        {
            'name': 'Ù…Ù‡Ø± Ø¹Ù…ÙˆÙ…ÛŒ',
            'url': 'https://www.mehrnews.com/rss/tp/1',
            'limit': 2
        },
        {
            'name': 'ØªØ³Ù†ÛŒÙ… Ø¹Ù…ÙˆÙ…ÛŒ',
            'url': 'https://www.tasnimnews.com/fa/rss/feed/0/110/0',
            'limit': 2
        }
    ]
    
    logger.info("ğŸ” ØªØ³Øª Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†...")
    
    working_sources = []
    
    for source in alternatives:
        logger.info(f"\nğŸ” ØªØ³Øª: {source['name']}")
        logger.info(f"ğŸ”— URL: {source['url']}")
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(source['url'], timeout=10) as response:
                    if response.status == 200:
                        content = await response.text()
                        if len(content) > 1000:  # Ø­Ø¯Ø§Ù‚Ù„ Ù…Ø­ØªÙˆØ§ÛŒ Ù…Ø¹ØªØ¨Ø±
                            logger.info(f"âœ… Ù…ÙˆÙÙ‚ - {len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
                            working_sources.append(source)
                        else:
                            logger.warning(f"âš ï¸ Ù…Ø­ØªÙˆØ§ÛŒ Ú©Ù… - {len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
                    else:
                        logger.error(f"âŒ HTTP {response.status}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§: {e}")
    
    logger.info(f"\nğŸ“Š Ù…Ù†Ø§Ø¨Ø¹ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø§Ø±Ú©Ø±Ø¯Ù‡:")
    for source in working_sources:
        logger.info(f"  âœ… {source['name']}")
    
    return working_sources

async def main():
    await check_fars_issue()
    await find_replacement_source()

if __name__ == "__main__":
    asyncio.run(main())