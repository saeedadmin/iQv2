#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ØªØ³Øª Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† vs Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†
"""

import asyncio
import aiohttp
from bs4 import BeautifulSoup

async def test_sorting_difference():
    """ØªØ³Øª ØªÙØ§ÙˆØª Ø¨ÛŒÙ† Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ùˆ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†"""
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    symbol = "BTCUSDT"
    
    # URL Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† (Ø¨Ø¯ÙˆÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±)
    popular_url = f"https://www.tradingview.com/symbols/{symbol}/ideas/"
    
    # URL Ø¨Ø±Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† (Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ± sort=recent)
    recent_url = f"https://www.tradingview.com/symbols/{symbol}/ideas/?sort=recent"
    
    print("ğŸ”¥ ØªØ³Øª Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§:")
    popular_links = await get_first_analysis_links(popular_url, headers)
    
    print("\n" + "="*50)
    print("ğŸ• ØªØ³Øª Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† ØªØ­Ù„ÛŒÙ„â€ŒÙ‡Ø§:")
    recent_links = await get_first_analysis_links(recent_url, headers)
    
    print("\n" + "="*50)
    print("ğŸ“Š Ù…Ù‚Ø§ÛŒØ³Ù‡ Ù†ØªØ§ÛŒØ¬:")
    
    if popular_links and recent_links:
        if popular_links[0] == recent_links[0]:
            print("âŒ Ù…Ø´Ú©Ù„: Ø§ÙˆÙ„ÛŒÙ† Ù„ÛŒÙ†Ú© Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ùˆ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† ÛŒÚ©Ø³Ø§Ù† Ø§Ø³Øª!")
            print(f"   Ù„ÛŒÙ†Ú© ÛŒÚ©Ø³Ø§Ù†: {popular_links[0]}")
        else:
            print("âœ… Ø¹Ø§Ù„ÛŒ: Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ† Ùˆ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ù…ØªÙØ§ÙˆØª Ù‡Ø³ØªÙ†Ø¯")
            print(f"   Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ†: {popular_links[0]}")
            print(f"   Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†: {recent_links[0]}")
    
    print(f"\nğŸ”— ØªØ¹Ø¯Ø§Ø¯ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø¨ÙˆØ¨â€ŒØªØ±ÛŒÙ†: {len(popular_links) if popular_links else 0}")
    print(f"ğŸ”— ØªØ¹Ø¯Ø§Ø¯ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ†: {len(recent_links) if recent_links else 0}")

async def get_first_analysis_links(url, headers, max_links=3):
    """Ø¯Ø±ÛŒØ§ÙØª Ø§ÙˆÙ„ÛŒÙ† Ú†Ù†Ø¯ Ù„ÛŒÙ†Ú© ØªØ­Ù„ÛŒÙ„ Ø§Ø² URL"""
    
    print(f"ğŸ” URL: {url}")
    
    try:
        timeout = aiohttp.ClientTimeout(total=15)
        async with aiohttp.ClientSession(timeout=timeout, headers=headers) as session:
            async with session.get(url) as response:
                if response.status == 200:
                    content = await response.text()
                    soup = BeautifulSoup(content, 'html.parser')
                    
                    idea_links = soup.find_all('a', href=True)
                    processed_urls = set()
                    found_links = []
                    
                    for link in idea_links:
                        href = link.get('href', '')
                        
                        # Ù…Ù†Ø·Ù‚ ÙØ¹Ù„ÛŒ Ù…Ø§
                        if ('/chart/' in href and 
                            '/' in href.split('/chart/')[-1] and 
                            any(char.isalnum() for char in href) and 
                            len(href.split('/chart/')[-1]) > 10 and
                            '-' in href.split('/chart/')[-1] and
                            '#chart-view-comment-form' not in href):
                            
                            clean_href = href.split('#')[0]
                            analysis_url = clean_href if clean_href.startswith('http') else f"https://www.tradingview.com{clean_href}"
                            
                            if analysis_url not in processed_urls:
                                processed_urls.add(analysis_url)
                                found_links.append(analysis_url)
                                
                                if len(found_links) <= max_links:
                                    print(f"  {len(found_links)}. {analysis_url}")
                                
                                if len(found_links) >= max_links:
                                    break
                    
                    return found_links
                
                else:
                    print(f"âŒ Ø®Ø·Ø§ÛŒ HTTP: {response.status}")
                    return []
                    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§: {e}")
        return []

if __name__ == "__main__":
    asyncio.run(test_sorting_difference())